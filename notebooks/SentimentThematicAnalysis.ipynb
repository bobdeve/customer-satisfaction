{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     24\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mshort_review\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str[:\u001b[32m512\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Step 5: Apply the sentiment analysis pipeline to each review\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# This will return a dictionary with 'label' (POSITIVE or NEGATIVE) and 'score' (confidence)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33msentiment_result\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshort_review\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Step 6: Extract 'label' and 'score' from the result dictionary into separate columns\u001b[39;00m\n\u001b[32m     31\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33msentiment_label\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33msentiment_result\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m])  \u001b[38;5;66;03m# POSITIVE or NEGATIVE\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\pandas\\core\\series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     24\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mshort_review\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mreview\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str[:\u001b[32m512\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Step 5: Apply the sentiment analysis pipeline to each review\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# This will return a dictionary with 'label' (POSITIVE or NEGATIVE) and 'score' (confidence)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33msentiment_result\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mshort_review\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43msentiment_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m])\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Step 6: Extract 'label' and 'score' from the result dictionary into separate columns\u001b[39;00m\n\u001b[32m     31\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33msentiment_label\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33msentiment_result\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m])  \u001b[38;5;66;03m# POSITIVE or NEGATIVE\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001b[39m, in \u001b[36mTextClassificationPipeline.__call__\u001b[39m\u001b[34m(self, inputs, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m inputs = (inputs,)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[32m    161\u001b[39m _legacy = \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\transformers\\pipelines\\base.py:1431\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1424\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1425\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m         )\n\u001b[32m   1429\u001b[39m     )\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\transformers\\pipelines\\base.py:1438\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1437\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\transformers\\pipelines\\base.py:1338\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1336\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1337\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:190\u001b[39m, in \u001b[36mTextClassificationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters.keys():\n\u001b[32m    189\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:931\u001b[39m, in \u001b[36mDistilBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    929\u001b[39m hidden_state = distilbert_output[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[32m    930\u001b[39m pooled_output = hidden_state[:, \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m pooled_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpre_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpooled_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n\u001b[32m    932\u001b[39m pooled_output = nn.ReLU()(pooled_output)  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n\u001b[32m    933\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bob\\Desktop\\10Acadamy\\week2\\customer-satisfaction\\webscraper\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Load your cleaned CSV\n",
    "# Step 2: Load your cleaned reviews dataset\n",
    "# Replace 'cleaned_reviews.csv' with your actual file name if it's different\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/raw/banks_review_cleaned.csv')\n",
    "# Display the first few rows to understand the structure\n",
    "df.head(50)\n",
    "\n",
    "\n",
    "# Step 3: Load the pre-trained sentiment analysis pipeline from HuggingFace Transformers\n",
    "# We're using a lightweight BERT model fine-tuned on SST-2 dataset for binary sentiment (positive/negative)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Step 4: Prepare review text\n",
    "# Ensure the review column is in string format and truncate long reviews to the first 512 characters\n",
    "# (Transformer models like BERT have a max token limit, usually around 512 tokens)\n",
    "df['short_review'] = df['review'].astype(str).str[:512]\n",
    "\n",
    "# Step 5: Apply the sentiment analysis pipeline to each review\n",
    "# This will return a dictionary with 'label' (POSITIVE or NEGATIVE) and 'score' (confidence)\n",
    "df['sentiment_result'] = df['short_review'].apply(lambda x: sentiment_pipeline(x)[0])\n",
    "\n",
    "# Step 6: Extract 'label' and 'score' from the result dictionary into separate columns\n",
    "df['sentiment_label'] = df['sentiment_result'].apply(lambda x: x['label'])  # POSITIVE or NEGATIVE\n",
    "df['sentiment_score'] = df['sentiment_result'].apply(lambda x: x['score'])  # Confidence score\n",
    "\n",
    "# Optional: Convert label to lowercase for consistency\n",
    "df['sentiment_label'] = df['sentiment_label'].str.lower()\n",
    "\n",
    "# Step 7: Preview the result\n",
    "print(df[['review', 'sentiment_label', 'sentiment_score']].head())\n",
    "\n",
    "# Step 8: Save the result to a new CSV for later use (e.g. thematic analysis)\n",
    "df.to_csv(\"../data/processed/bank_reviews_with_sentiment.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Bob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This movie was  good, but the ending was AMAZING!!\n",
      "Sentiment: Positive\n",
      "Compound Score: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Bob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example text\n",
    "text = \"This movie was very good, but the ending was AMAZING!!\"\n",
    "score = analyzer.polarity_scores(text)\n",
    "\n",
    "compound = score['compound']\n",
    "\n",
    "# Classify based on compound score\n",
    "if compound >= 0.05:\n",
    "    sentiment = \"Positive\"\n",
    "elif compound <= -0.05:\n",
    "    sentiment = \"Negative\"\n",
    "else:\n",
    "    sentiment = \"Neutral\"\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Sentiment: {sentiment}\")\n",
    "print(f\"Compound Score: {compound}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>bank</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Why don‚Äôt your ATMs support account-to-accoun...</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is this app problem???</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the app is proactive and a good connections.</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I cannot send to cbebirr app. through this app.</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>not functional</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>everytime you uninstall the app you have to re...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The name of our account is the name of our acc...</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>best</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bezabih</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Best Mobile Banking app ever</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>good</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it was good app but it have some issues like i...</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>good</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>very niec</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>best app of finance</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>YETEMETA</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Engida Kebede Fetera</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>good</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>it is not safety</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NICE bank</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>it is like a childish app make it better the w...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>It's a problem solver application, go ahead CB...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>It's good but try to make it facilitate for yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>best app</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Awesome bank</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>this app has developed in a very good ways but...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Masha all</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Recently there is big problem when sending to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>better service</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>it,s good app and time manager üëç</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Malkaamuu wet people</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lower system everything</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Nice!</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Keep it up My CBE</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>yes good</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I was using this app for the last two years wi...</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>i like everything of this app</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>good</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ü§¨ü§¨ü§¨ü§¨ network üõú</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Best</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CBE is the best financial application and and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>nice</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>good job</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>it's awesome!!</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>best</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>thankyou every one</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>best app</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-25</td>\n",
       "      <td>CBE</td>\n",
       "      <td>Google Play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  rating        date  \\\n",
       "0   \"Why don‚Äôt your ATMs support account-to-accoun...       4  2025-06-06   \n",
       "1                         what is this app problem???       1  2025-06-05   \n",
       "2        the app is proactive and a good connections.       5  2025-06-05   \n",
       "3     I cannot send to cbebirr app. through this app.       3  2025-06-05   \n",
       "4                                                good       4  2025-06-05   \n",
       "5                                      not functional       1  2025-06-05   \n",
       "6   everytime you uninstall the app you have to re...       1  2025-06-04   \n",
       "7   The name of our account is the name of our acc...       4  2025-06-04   \n",
       "8                                                best       5  2025-06-04   \n",
       "9                                             Bezabih       5  2025-06-04   \n",
       "10                       Best Mobile Banking app ever       5  2025-06-04   \n",
       "11                                               good       5  2025-06-04   \n",
       "12  it was good app but it have some issues like i...       2  2025-06-04   \n",
       "13                                               good       5  2025-06-04   \n",
       "14                                               Good       5  2025-06-04   \n",
       "15                                          very niec       5  2025-06-04   \n",
       "16                                best app of finance       5  2025-06-04   \n",
       "17                                           YETEMETA       1  2025-06-03   \n",
       "18                               Engida Kebede Fetera       5  2025-06-03   \n",
       "19                                               good       5  2025-06-03   \n",
       "20                                   it is not safety       1  2025-06-03   \n",
       "21                                          NICE bank       5  2025-06-03   \n",
       "22  it is like a childish app make it better the w...       1  2025-06-02   \n",
       "23  It's a problem solver application, go ahead CB...       5  2025-06-02   \n",
       "24  It's good but try to make it facilitate for yo...       4  2025-06-02   \n",
       "25                                           best app       5  2025-06-01   \n",
       "26                                       Awesome bank       5  2025-06-01   \n",
       "27  this app has developed in a very good ways but...       5  2025-05-31   \n",
       "28                                          Masha all       5  2025-05-31   \n",
       "29  Recently there is big problem when sending to ...       2  2025-05-31   \n",
       "30                                     better service       5  2025-05-31   \n",
       "31                   it,s good app and time manager üëç       5  2025-05-30   \n",
       "32                               Malkaamuu wet people       5  2025-05-30   \n",
       "33                            lower system everything       3  2025-05-30   \n",
       "34                                              Nice!       5  2025-05-30   \n",
       "35                                  Keep it up My CBE       5  2025-05-29   \n",
       "36                                           yes good       5  2025-05-28   \n",
       "37  I was using this app for the last two years wi...       4  2025-05-27   \n",
       "38                      i like everything of this app       5  2025-05-27   \n",
       "39                                               good       5  2025-05-27   \n",
       "40                                     ü§¨ü§¨ü§¨ü§¨ network üõú       1  2025-05-26   \n",
       "41                                               Best       5  2025-05-26   \n",
       "42  CBE is the best financial application and and ...       5  2025-05-26   \n",
       "43                                               nice       5  2025-05-26   \n",
       "44                                           good job       5  2025-05-26   \n",
       "45                                               Good       5  2025-05-25   \n",
       "46                                     it's awesome!!       5  2025-05-25   \n",
       "47                                               best       5  2025-05-25   \n",
       "48                                 thankyou every one       5  2025-05-25   \n",
       "49                                           best app       5  2025-05-25   \n",
       "\n",
       "   bank       source  \n",
       "0   CBE  Google Play  \n",
       "1   CBE  Google Play  \n",
       "2   CBE  Google Play  \n",
       "3   CBE  Google Play  \n",
       "4   CBE  Google Play  \n",
       "5   CBE  Google Play  \n",
       "6   CBE  Google Play  \n",
       "7   CBE  Google Play  \n",
       "8   CBE  Google Play  \n",
       "9   CBE  Google Play  \n",
       "10  CBE  Google Play  \n",
       "11  CBE  Google Play  \n",
       "12  CBE  Google Play  \n",
       "13  CBE  Google Play  \n",
       "14  CBE  Google Play  \n",
       "15  CBE  Google Play  \n",
       "16  CBE  Google Play  \n",
       "17  CBE  Google Play  \n",
       "18  CBE  Google Play  \n",
       "19  CBE  Google Play  \n",
       "20  CBE  Google Play  \n",
       "21  CBE  Google Play  \n",
       "22  CBE  Google Play  \n",
       "23  CBE  Google Play  \n",
       "24  CBE  Google Play  \n",
       "25  CBE  Google Play  \n",
       "26  CBE  Google Play  \n",
       "27  CBE  Google Play  \n",
       "28  CBE  Google Play  \n",
       "29  CBE  Google Play  \n",
       "30  CBE  Google Play  \n",
       "31  CBE  Google Play  \n",
       "32  CBE  Google Play  \n",
       "33  CBE  Google Play  \n",
       "34  CBE  Google Play  \n",
       "35  CBE  Google Play  \n",
       "36  CBE  Google Play  \n",
       "37  CBE  Google Play  \n",
       "38  CBE  Google Play  \n",
       "39  CBE  Google Play  \n",
       "40  CBE  Google Play  \n",
       "41  CBE  Google Play  \n",
       "42  CBE  Google Play  \n",
       "43  CBE  Google Play  \n",
       "44  CBE  Google Play  \n",
       "45  CBE  Google Play  \n",
       "46  CBE  Google Play  \n",
       "47  CBE  Google Play  \n",
       "48  CBE  Google Play  \n",
       "49  CBE  Google Play  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../data/raw/banks_review_cleaned.csv')\n",
    "# Display the first few rows to understand the structure\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      bank  rating  mean_sentiment_score  mean_sentiment_label_numeric  \\\n",
      "0      BOA       1              0.986962                     -0.773585   \n",
      "1      BOA       2              0.933640                     -0.750000   \n",
      "2      BOA       3              0.976630                     -0.085714   \n",
      "3      BOA       4              0.964666                      0.000000   \n",
      "4      BOA       5              0.971614                      0.584541   \n",
      "5      CBE       1              0.976445                     -0.622642   \n",
      "6      CBE       2              0.997675                     -0.294118   \n",
      "7      CBE       3              0.986456                     -0.310345   \n",
      "8      CBE       4              0.963908                     -0.043478   \n",
      "9      CBE       5              0.986866                      0.794286   \n",
      "10  Dashen       1              0.995235                     -0.882353   \n",
      "11  Dashen       2              0.981517                     -0.647059   \n",
      "12  Dashen       3              0.997640                      0.000000   \n",
      "13  Dashen       4              0.994449                      0.333333   \n",
      "14  Dashen       5              0.991516                      0.837535   \n",
      "\n",
      "    percent_positive  review_count  \n",
      "0          11.320755           211  \n",
      "1          12.500000            16  \n",
      "2          45.714286            34  \n",
      "3          50.000000            18  \n",
      "4          79.227053           207  \n",
      "5          18.867925            53  \n",
      "6          35.294118            17  \n",
      "7          34.482759            29  \n",
      "8          47.826087            46  \n",
      "9          89.714286           350  \n",
      "10          5.882353            34  \n",
      "11         17.647059            17  \n",
      "12         50.000000            12  \n",
      "13         66.666667            24  \n",
      "14         91.876751           357  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../data/raw/banks_review_cleaned.csv')\n",
    "# Display the first few rows to understand the structure\n",
    "df.head(10)\n",
    "\n",
    "df['short_review'] = df['review'].astype(str).str[:512]\n",
    "# Step 6 (continued): Extract the sentiment label and score from the output dictionary\n",
    "df['sentiment_result'] = df['short_review'].apply(lambda x: sentiment_pipeline(x)[0])\n",
    "# Create a new column 'sentiment_label' with the value: POSITIVE or NEGATIVE\n",
    "df['sentiment_label'] = df['sentiment_result'].apply(lambda x: x['label'])\n",
    "\n",
    "# Create a new column 'sentiment_score' which is the model's confidence in its prediction (between 0 and 1)\n",
    "df['sentiment_score'] = df['sentiment_result'].apply(lambda x: x['score'])\n",
    "\n",
    "# Optional: Map sentiment labels to numerical values for easier aggregation\n",
    "# POSITIVE -> 1, NEGATIVE -> -1 (you can also use 0 and 1 if preferred)\n",
    "df['sentiment_numeric'] = df['sentiment_label'].map({'POSITIVE': 1, 'NEGATIVE': -1})\n",
    "\n",
    "# Step 7: Group and aggregate sentiment by bank and star rating\n",
    "# We calculate:\n",
    "# - The average sentiment score\n",
    "# - The proportion of positive reviews\n",
    "# - Total number of reviews in that group (for context)\n",
    "\n",
    "sentiment_summary = df.groupby(['bank', 'rating']).agg(\n",
    "    mean_sentiment_score=('sentiment_score', 'mean'),\n",
    "    mean_sentiment_label_numeric=('sentiment_numeric', 'mean'),\n",
    "    percent_positive=('sentiment_label', lambda x: (x == 'POSITIVE').mean() * 100),\n",
    "    review_count=('review', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Display the summary\n",
    "print(sentiment_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top Thematic Keywords from Reviews:\n",
      "               term     score\n",
      "385            good  0.112085\n",
      "41              app  0.073632\n",
      "165            best  0.050803\n",
      "644            nice  0.038064\n",
      "139            bank  0.024281\n",
      "166        best app  0.020417\n",
      "658              ok  0.019762\n",
      "987             wow  0.018982\n",
      "308       excellent  0.017222\n",
      "515            like  0.016630\n",
      "931             use  0.016626\n",
      "386        good app  0.016345\n",
      "157         banking  0.016117\n",
      "403           great  0.015948\n",
      "974            work  0.015242\n",
      "325            fast  0.014396\n",
      "118     application  0.014150\n",
      "291            easy  0.013905\n",
      "240          dashen  0.013863\n",
      "22          amazing  0.013760\n",
      "976         working  0.012112\n",
      "862           super  0.011800\n",
      "196             cbe  0.011305\n",
      "598          mobile  0.011165\n",
      "182             boa  0.010922\n",
      "981           worst  0.009053\n",
      "889           thank  0.008861\n",
      "280           doesn  0.008262\n",
      "601  mobile banking  0.008258\n",
      "241     dashen bank  0.008142\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Use short version of the review or full version\n",
    "texts = df['short_review'].fillna(\"\")\n",
    "\n",
    "# Step 2: Create a TF-IDF Vectorizer\n",
    "# We use unigrams, bigrams, and trigrams (1 to 3-word phrases)\n",
    "# This helps extract phrases like \"login error\", \"transfer failed\", \"slow app\"\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), \n",
    "                             stop_words='english',  # remove common words\n",
    "                             max_features=1000)     # limit to top 1000 keywords\n",
    "\n",
    "# Step 3: Fit the vectorizer and transform the reviews into TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Step 4: Get top n keywords by average TF-IDF score across all reviews\n",
    "import numpy as np\n",
    "\n",
    "# Compute mean tf-idf score for each feature (keyword/ngram)\n",
    "mean_tfidf = np.asarray(tfidf_matrix.mean(axis=0)).flatten()\n",
    "\n",
    "# Map scores to terms\n",
    "tfidf_scores = pd.DataFrame({\n",
    "    'term': vectorizer.get_feature_names_out(),\n",
    "    'score': mean_tfidf\n",
    "})\n",
    "\n",
    "# Sort to get top themes\n",
    "top_keywords = tfidf_scores.sort_values(by='score', ascending=False).head(30)\n",
    "print(\"üîç Top Thematic Keywords from Reviews:\")\n",
    "print(top_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: good, app, work, ok, better, boa, make, working, update, don\n",
      "Topic #2: app, super, dashen, fast, super app, user, easy, dashen bank, features, banking\n",
      "Topic #3: app, best, best app, good, good app, like, use, banking, bank, worst\n",
      "Topic #4: app, bank, nice, cbe, wow, great, dashen, step, developer, dashen bank\n",
      "Topic #5: app, mobile, banking, mobile banking, work, doesn, application, amazing, doesn work, excellent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Step 1: Prepare review text (same as before)\n",
    "texts = df['short_review'].fillna(\"\")\n",
    "\n",
    "# Step 2: Convert text into a document-term matrix\n",
    "# Using unigrams and bigrams to capture phrases like \"login error\"\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2), max_features=1000)\n",
    "dtm = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Step 3: Apply LDA to discover topics\n",
    "n_topics = 5  # You can tweak this based on results\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "# Step 4: Print top keywords in each topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def get_top_keywords(model, feature_names, n_top_words):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_keywords = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topics.append(top_keywords)\n",
    "        print(f\"Topic #{topic_idx + 1}: {', '.join(top_keywords)}\")\n",
    "    return topics\n",
    "\n",
    "# Get top 10 words per topic\n",
    "topics = get_top_keywords(lda, feature_names, n_top_words=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample reviews\n",
    "texts = df['short_review'].fillna(\"\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_review'] = texts.apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "df['sentiment'] = df['short_review'].apply(lambda x: sentiment_pipeline(x)[0]['label'] if isinstance(x, str) else None)\n",
    "df['sentiment_score'] = df['short_review'].apply(lambda x: sentiment_pipeline(x)[0]['score'] if isinstance(x, str) else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Extract top keywords\n",
    "vectorizer = TfidfVectorizer(max_features=20, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# Add top keywords to DataFrame\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "tfidf_matrix = pd.DataFrame(X.toarray(), columns=keywords)\n",
    "df_keywords = pd.concat([df, tfidf_matrix], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mapping logic based on top LDA keywords\n",
    "def map_to_theme(text):\n",
    "    text = text.lower()\n",
    "    if \"login\" in text or \"access\" in text or \"otp\" in text:\n",
    "        return \"Account Access Issues\"\n",
    "    elif \"slow\" in text or \"transfer\" in text or \"transaction\" in text:\n",
    "        return \"Transaction Performance\"\n",
    "    elif \"ui\" in text or \"interface\" in text or \"design\" in text:\n",
    "        return \"User Interface & Experience\"\n",
    "    elif \"support\" in text or \"help\" in text or \"response\" in text:\n",
    "        return \"Customer Support\"\n",
    "    elif \"feature\" in text or \"request\" in text:\n",
    "        return \"Feature Request\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df['theme'] = df['cleaned_review'].apply(map_to_theme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[['short_review', 'cleaned_review', 'sentiment', 'sentiment_score', 'theme', 'bank', 'rating', 'date', 'source']]\n",
    "df_final.to_csv(\"../data/processed/bank_review_sentiment_theme.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
