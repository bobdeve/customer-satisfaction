{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Scraping reviews for CBE...\n",
      "📥 Scraping reviews for BOA...\n",
      "📥 Scraping reviews for Dashen...\n",
      "✅ Scraping and cleaning complete! Data saved to: ../data/raw\\bank_reviews_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# 📦 Step 1: Import required libraries\n",
    "# ----------------------------------------\n",
    "from google_play_scraper import reviews, Sort       # To scrape Google Play app reviews\n",
    "import pandas as pd                                 # For data manipulation and analysis\n",
    "from datetime import datetime                       # To normalize and format dates\n",
    "import os                                           # For creating folders and managing paths\n",
    "\n",
    "# ----------------------------------------\n",
    "# 🏦 Step 2: Define target apps and corresponding bank names\n",
    "# ----------------------------------------\n",
    "# This dictionary maps each app's package name (used for scraping)\n",
    "# to a human-readable bank name for clarity in the dataset\n",
    "apps = {\n",
    "    'com.combanketh.mobilebanking': 'CBE',       # Commercial Bank of Ethiopia\n",
    "    'com.boa.boaMobileBanking': 'BOA',           # Bank of Abyssinia\n",
    "    'com.dashen.dashensuperapp': 'Dashen'        # Dashen Bank\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# 📁 Step 3: Ensure directory for raw data exists\n",
    "# ----------------------------------------\n",
    "# Create a folder structure: data/raw\n",
    "output_dir = os.path.join('../data/raw')          # Set the desired path\n",
    "os.makedirs(output_dir, exist_ok=True)            # Create the folder if it doesn't exist\n",
    "\n",
    "# ----------------------------------------\n",
    "# 🧺 Step 4: Initialize a list to store all reviews\n",
    "# ----------------------------------------\n",
    "# We'll append each app's reviews as a DataFrame to this list and combine them later\n",
    "all_reviews = []\n",
    "\n",
    "# ----------------------------------------\n",
    "# 🔁 Step 5: Loop through each app and scrape reviews\n",
    "# ----------------------------------------\n",
    "for package_name, bank_name in apps.items():\n",
    "    print(f\"📥 Scraping reviews for {bank_name}...\")\n",
    "\n",
    "    # Use google_play_scraper to fetch up to ~500 recent reviews\n",
    "    reviews_list, _ = reviews(\n",
    "        package_name,               # App identifier\n",
    "        lang='en',                  # Language: English\n",
    "        country='us',               # Country: US (change to 'et' for Ethiopia if needed)\n",
    "        sort=Sort.NEWEST,           # Get the most recent reviews\n",
    "        count=500                   # Number of reviews to fetch\n",
    "    )\n",
    "\n",
    "    # Convert list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(reviews_list)\n",
    "\n",
    "    # Add custom columns for 'bank' and 'source' (Google Play)\n",
    "    df['bank'] = bank_name\n",
    "    df['source'] = 'Google Play'\n",
    "\n",
    "    # Append this bank's reviews to the main list\n",
    "    all_reviews.append(df)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 📊 Step 6: Combine all banks' data into a single DataFrame\n",
    "# ----------------------------------------\n",
    "combined_df = pd.concat(all_reviews, ignore_index=True)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 🧹 Step 7: Preprocess the data\n",
    "# ----------------------------------------\n",
    "\n",
    "# 7.1 Remove duplicate rows based on content (e.g., review content + userName)\n",
    "combined_df.drop_duplicates(subset=['content', 'userName'], inplace=True)\n",
    "\n",
    "# 7.2 Handle missing values — remove rows where 'content' or 'score' is missing\n",
    "combined_df.dropna(subset=['content', 'score'], inplace=True)\n",
    "\n",
    "# 7.3 Normalize the date format — convert 'at' column to YYYY-MM-DD\n",
    "combined_df['date'] = pd.to_datetime(combined_df['at']).dt.date\n",
    "\n",
    "# ----------------------------------------\n",
    "# 📦 Step 8: Select and rename the required columns\n",
    "# ----------------------------------------\n",
    "final_df = combined_df[['content', 'score', 'date', 'bank', 'source']]\n",
    "final_df.columns = ['review', 'rating', 'date', 'bank', 'source']  # Rename columns\n",
    "\n",
    "# ----------------------------------------\n",
    "# 💾 Step 9: Save cleaned data to CSV\n",
    "# ----------------------------------------\n",
    "csv_path = os.path.join(output_dir, 'bank_reviews_cleaned.csv')\n",
    "final_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# ✅ Done\n",
    "print(f\"✅ Scraping and cleaning complete! Data saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Number of reviews per bank:\n",
      "bank\n",
      "CBE       500\n",
      "BOA       499\n",
      "Dashen    446\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../data/raw/bank_reviews_cleaned.csv')\n",
    "\n",
    "# Count the number of reviews for each bank\n",
    "bank_counts = df['bank'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"📊 Number of reviews per bank:\")\n",
    "print(bank_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
